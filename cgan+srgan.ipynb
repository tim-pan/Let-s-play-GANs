{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU State: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from evaluator import evaluation_model as pre_cla\n",
    "import copy\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import dataset\n",
    "from dataset import *\n",
    "from tqdm import tqdm \n",
    "import torch.nn.utils.spectral_norm as spectral_norm \n",
    "import torch\n",
    "\n",
    "\n",
    "'''\n",
    "this model implement simplest cgan, that is:\n",
    "concatnate latent and label together\n",
    "and send it into generator\n",
    "this file use spectral normalization instead of bn\n",
    "https://christiancosgrove.com/blog/2018/01/04/spectral-normalization-explained.html\n",
    "'''\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "        \n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.block1 = nn.Conv2d(self.channels, self.channels, 3, padding=1)\n",
    "#         nn.init.xavier_normal_(self.block1.weight)\n",
    "        \n",
    "        self.block2 = nn.Conv2d(self.channels, self.channels, 3, padding=1)\n",
    "#         nn.init.xavier_normal_(self.block2.weight)\n",
    "        \n",
    "        self.act = nn.PReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(self.channels)\n",
    "        self.bn2 = nn.BatchNorm2d(self.channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.block1(x)\n",
    "        residual = self.bn1(residual)\n",
    "        residual = self.act(residual)\n",
    "        residual = self.block2(residual)\n",
    "        residual = self.bn2(residual)\n",
    "        return x + residual\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, up_scale):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, kernel_size=3, padding=1)\n",
    "#         nn.init.xavier_normal_(self.conv.weight)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
    "        \n",
    "        self.act = nn.PReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "    \n",
    "class generator(nn.Module):\n",
    "    '''\n",
    "    input:\n",
    "    noise:[bs, z_dim] this is randomly generated by yourself\n",
    "    labels:[bs, 24]\n",
    "    for eg:bs=3 labels = [[0, 1, 1, 0, ..., 0], \n",
    "                          [1, 0, 0, 0, ..., 1],\n",
    "                          [0, 0, 0, 1, ..., 0]]\n",
    "    return:\n",
    "    a [bs, 3, img_size, img_size] image\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_classes, img_size, z_dim, upsample_block_num, c_dim=256):\n",
    "        super(generator, self).__init__()\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.z_dim = z_dim\n",
    "        self.in_size = n_classes + z_dim\n",
    "        self.img_size = img_size\n",
    "        self.upsample_block_num = upsample_block_num\n",
    "        self.c_dim = c_dim\n",
    "        \n",
    "#         self.label_emb = nn.Embedding(self.n_classes, self.n_classes)\n",
    "#如果真的要算，embedding感覺無法work了，就直接用onehot吧\n",
    "        self.conditionExpand=nn.Sequential(\n",
    "            nn.Linear(24, self.c_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(self.c_dim + z_dim, 64, 9, padding = 4),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "#         nn.init.xavier_normal_(self.block1[0].weight)\n",
    "        \n",
    "        self.block2 = ResidualBlock(64)\n",
    "        self.block3 = ResidualBlock(64)\n",
    "        self.block4 = ResidualBlock(64)\n",
    "        self.block5 = ResidualBlock(64)\n",
    "        self.block6 = ResidualBlock(64)\n",
    "\n",
    "        self.block7 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "#         nn.init.xavier_normal_(self.block7[0].weight),\n",
    "        \n",
    "        \n",
    "        block8 = [UpsampleBlock(64, 2) for _ in range(self.upsample_block_num)]\n",
    "        #decide how many times tdo you want to upsample\n",
    "        \n",
    "#         nn.init.xavier_normal_(self.c.weight)\n",
    "        block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n",
    "        self.block8 = nn.Sequential(*block8)\n",
    "\n",
    "        \n",
    "    def forward(self, noise, labels):\n",
    "        #noise should be a [bs, z_dim] dim tensor! RANDOM CHOOSE!\n",
    "        #https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/cgan/cgan.py\n",
    "        #gen_input is a [bs, z_dim+n_classes, 1, 1] tensor!\n",
    "        \n",
    "        # Concatenate label embedding and image to produce input\n",
    "#         gen_input = torch.cat((self.label_emb(labels), noise), -1)#(bs, feature_dim(z_dim + n_classes))\n",
    "        # Concatenate onehot label and image to produce input\n",
    "        labels = self.conditionExpand(labels.float())#[bs, 256]\n",
    "        gen_input = torch.cat((noise, labels), -1)#(bs, feature_dim(z_dim + n_classes))\n",
    "        gen_input = gen_input.view(gen_input.size(0), gen_input.size(-1), 1, 1)#(bs, feat_dim, 1, 1)\n",
    "        \n",
    "        block1 = self.block1(gen_input)\n",
    "        block2 = self.block2(block1)\n",
    "        block3 = self.block3(block2)\n",
    "        block4 = self.block4(block3)\n",
    "        block5 = self.block5(block4)\n",
    "        block6 = self.block6(block5)\n",
    "        block7 = self.block7(block6)\n",
    "        \n",
    "        block8 = self.block8(block1 + block7)\n",
    "\n",
    "        return (torch.tanh(block8) + 1) / 2\n",
    "    \n",
    "    \n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self, n_classes, img_size):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.img_size = img_size#default:64\n",
    "        self.n_classes = n_classes\n",
    "#         self.label_embedding = nn.Embedding(self.n_classes, self.n_classes)\n",
    "#因為一個照片不只要一個label, 這沒用了\n",
    "        \n",
    "        self.convert_label_layer = nn.Sequential(\n",
    "            nn.Linear(self.n_classes, self.img_size**2),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(4, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(512, 1024, kernel_size=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(1024, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        '''\n",
    "        input:\n",
    "        img:[bs, 3, img_size=64, img_size=64]\n",
    "        labels:[bs, 24], similar to above\n",
    "        \n",
    "        return:[bs] tensor for true prob\n",
    "        '''\n",
    "        # Concatenate label and image to produce input\n",
    "#         c = self.convert_label_layer(self.label_embedding(labels)).reshape(-1, 1, self.img_size, self.img_size\n",
    "        c = self.convert_label_layer(labels.float()).view(-1, 1, self.img_size, self.img_size)#(bs, 1, imgsize, imgsize)\n",
    "        out = torch.cat((img, c), 1)#concatenate img tensor and c(label) tensor\n",
    "        \n",
    "        out = self.net(out).view(out.size(0)) \n",
    "        \n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################LOSS part########################################\n",
    "class GeneratorLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorLoss, self).__init__()\n",
    "        vgg = models.vgg16(pretrained=True)\n",
    "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
    "        for param in loss_network.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.loss_network = loss_network\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "#         self.L1loss = nn.L1Loss()\n",
    "        self.tv_loss = TVLoss()\n",
    "\n",
    "    def forward(self, out_labels, out_images, target_images):\n",
    "        # Adversarial Loss\n",
    "        adversarial_loss = nn.BCELoss()(out_labels, smooth_label('real', out_labels.shape))\n",
    "        # Perception Loss\n",
    "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
    "        # Image Loss\n",
    "        image_loss = self.mse_loss(out_images, target_images)\n",
    "        # TV Loss\n",
    "        tv_loss = self.tv_loss(out_images)\n",
    "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
    "#         return adversarial_loss\n",
    "\n",
    "# introduction of tv loss: https://www.daimajiaoliu.com/daima/479773d4d1003fe\n",
    "class TVLoss(nn.Module):\n",
    "    def __init__(self, tv_loss_weight=1):\n",
    "        super(TVLoss, self).__init__()\n",
    "        self.tv_loss_weight = tv_loss_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size()[0]\n",
    "        h_x = x.size()[2]\n",
    "        w_x = x.size()[3]\n",
    "        count_h = self.tensor_size(x[:, :, 1:, :])\n",
    "        count_w = self.tensor_size(x[:, :, :, 1:])\n",
    "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
    "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
    "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.size()[1] * t.size()[2] * t.size()[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "\n",
    "def random_z(batch_size, z_dim):\n",
    "    return torch.randn(batch_size, z_dim, device=device)\n",
    "\n",
    "def save_img(images, path):\n",
    "    out = make_grid(images)\n",
    "    save_image(out, path)\n",
    "def smooth_label(mode, shape):\n",
    "    \n",
    "    if mode == 'real':\n",
    "        return (torch.rand(shape, device=device) / 10) + 0.9\n",
    "    elif mode == 'fake':\n",
    "        return torch.rand(shape, device=device) / 10\n",
    "\n",
    "\n",
    "def train(G, D, epochs,lr_g, lr_d, train_loader, test_loader):\n",
    "#     adversarial_criterion=nn.BCELoss().to(device)\n",
    "    generator_criterion = GeneratorLoss().to(device)\n",
    "    \n",
    "    total_loss_g = 0\n",
    "    total_loss_d = 0\n",
    "    num = 0\n",
    "    best_score = 0\n",
    "    \n",
    "    test_label = next(iter(test_loader)).to(device)#[bs, 24]\n",
    "    test_z = random_z(test_label.size(0), z_dim).to(device)\n",
    "    \n",
    "    G.train().to(device)\n",
    "    D.train().to(device)\n",
    "    \n",
    "    G.apply(weights_init_normal)\n",
    "    D.apply(weights_init_normal)\n",
    "    \n",
    "    optimizer_g = optim.Adam(G.parameters(), lr=lr_g, betas=(0, 0.9))\n",
    "    optimizer_d = optim.Adam(D.parameters(), lr=lr_d, betas=(0, 0.9))\n",
    "    \n",
    "    \n",
    "    for epoch in range(1, epochs):\n",
    "        num=0\n",
    "        \n",
    "        for image, label in tqdm(train_loader):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            num += label.size(0)\n",
    "            real = image\n",
    "            \n",
    "            ############################\n",
    "            #   Update D network: maximize D(x)-1-D(G(z))  \n",
    "            ############################\n",
    "                \n",
    "            fake_img = G(random_z(label.size(0), z_dim), label)\n",
    "            \n",
    "            optimizer_d.zero_grad()\n",
    "            real_out = D(real, label)\n",
    "            fake_out = D(fake_img, label)\n",
    "            \n",
    "            loss_real = nn.BCELoss()(real_out, smooth_label('real', real_out.shape))\n",
    "            loss_fake = nn.BCELoss()(fake_out, smooth_label('fake', fake_out.shape))\n",
    "#             real_out = D(real, label).mean()\n",
    "#             fake_out = D(fake_img, label).mean()\n",
    "#             loss_d = 1 - real_out + fake_out\n",
    "            loss_d = loss_real + loss_fake\n",
    "\n",
    "\n",
    "            total_loss_d += loss_d.item()\n",
    "            loss_d.backward(retain_graph=True)\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            ############################\n",
    "            #   Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
    "            ############################\n",
    "            #generate fake img\n",
    "            optimizer_g.zero_grad()\n",
    "\n",
    "            fake_img = G(random_z(label.size(0), z_dim), label)\n",
    "            fake_out = D(fake_img, label)\n",
    "            ##\n",
    "            loss_g = generator_criterion(fake_out, fake_img, real)\n",
    "            loss_g.backward()\n",
    "\n",
    "            optimizer_g.step()\n",
    "\n",
    "            total_loss_g += loss_g.item()\n",
    "            \n",
    "        # evaluate    \n",
    "        G.eval()\n",
    "        D.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            gen_imgs = G(test_z, test_label)\n",
    "        score = pre_cla().eval(gen_imgs, test_label)\n",
    "        gen_imgs = denorm(gen_imgs, device)\n",
    "        \n",
    "        if score >= best_score:\n",
    "            best_score = score\n",
    "            best_model_wts = copy.deepcopy(G.state_dict())\n",
    "            torch.save(best_model_wts, os.path.join('cgan_srgan', 'paras_sn', f'epoch{epoch}_score{score:.2f}.pth'))\n",
    "        print(f\"Epoch[{epoch}/{epochs}]\")\n",
    "        total_loss_d /= num\n",
    "        total_loss_g /= num\n",
    "        \n",
    "        print(f'score: {score}')\n",
    "        print(f'generator_loss:{total_loss_g:.8f}')\n",
    "        print(f'discriminator_loss:{total_loss_d:.8f}')\n",
    "        print()\n",
    "        # savefig\n",
    "        save_image(gen_imgs, os.path.join('cgan_srgan', 'results_sn', f'epoch{epoch}.png'), nrow=8, normalize=False)\n",
    "               \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 18009 images...\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "from dataset import *\n",
    "\n",
    "root_folder = 'data'\n",
    "z_dim = 100\n",
    "n_classes = 24\n",
    "img_size = 64\n",
    "batch_size = 32\n",
    "upsample_block_num = 6\n",
    "epochs = 200\n",
    "lr_d = 0.00004\n",
    "lr_g = 0.00001\n",
    "\n",
    "train_set = ICLEVRLoader(root_folder, mode = 'train')\n",
    "test_set = ICLEVRLoader(root_folder, mode = 'test')\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                         )\n",
    "test_loader = DataLoader(test_set,\n",
    "                          batch_size=32,\n",
    "                          shuffle=False,\n",
    "                         )\n",
    "\n",
    "G = generator(n_classes, img_size, z_dim, upsample_block_num)\n",
    "D = discriminator(24, 64)\n",
    "\n",
    "\n",
    "# train(G, D, epochs, lr_g, lr_d, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
